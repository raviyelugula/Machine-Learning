library(dplyr)
library(purrr)
library(twitteR)
install.packages('dplyr')
installed.packages(purrr)
installed.packages('purrr')
install.packages('twitteR')
install.packages('tidyr')
install.packages('lubridate')
install.packages('scales')
install.packages('tidytext')
install.packages('broom')
library("purrr", lib.loc="~/R/win-library/3.3")
library(dplyr)
library(purrr)
library(twitteR)
setup_twitter_oauth(getOption("YrOyTk5s9mBVkCNxjsL6QAAvR"),
getOption("	zOl3g5slS8fIBw1hWU3a8zeU1BFcS3g1wz7drIz2lbC8mydmgG"),
getOption("191958252-uOisKMkvWHWmiTRQnf9d6XMww5wtZVtox1ShcjMm"),
getOption("9kTTYtORX4KnXk9SG4R9bQ1PpmQyBYEwmfvDksTh6Wht0"))
setup_twitter_oauth(getOption("YrOyTk5s9mBVkCNxjsL6QAAvR"),
getOption("	zOl3g5slS8fIBw1hWU3a8zeU1BFcS3g1wz7drIz2lbC8mydmgG"),
getOption("191958252-uOisKMkvWHWmiTRQnf9d6XMww5wtZVtox1ShcjMm"),
getOption("9kTTYtORX4KnXk9SG4R9bQ1PpmQyBYEwmfvDksTh6Wht0"))
setup_twitter_oauth(getOption("YrOyTk5s9mBVkCNxjsL6QAAvR"),
getOption("	zOl3g5slS8fIBw1hWU3a8zeU1BFcS3g1wz7drIz2lbC8mydmgG"),
getOption("191958252-uOisKMkvWHWmiTRQnf9d6XMww5wtZVtox1ShcjMm"),
getOption("9kTTYtORX4KnXk9SG4R9bQ1PpmQyBYEwmfvDksTh6Wht0"))
setup_twitter_oauth("YrOyTk5s9mBVkCNxjsL6QAAvR",
"	zOl3g5slS8fIBw1hWU3a8zeU1BFcS3g1wz7drIz2lbC8mydmgG",
"191958252-uOisKMkvWHWmiTRQnf9d6XMww5wtZVtox1ShcjMm",
"9kTTYtORX4KnXk9SG4R9bQ1PpmQyBYEwmfvDksTh6Wht0")
options(httr_oauth_cache=T)
setup_twitter_oauth("YrOyTk5s9mBVkCNxjsL6QAAvR",
"	zOl3g5slS8fIBw1hWU3a8zeU1BFcS3g1wz7drIz2lbC8mydmgG",
"191958252-uOisKMkvWHWmiTRQnf9d6XMww5wtZVtox1ShcjMm",
"9kTTYtORX4KnXk9SG4R9bQ1PpmQyBYEwmfvDksTh6Wht0")
install.packages("httr", dependencies = TRUE)
install.packages("httr", dependencies = TRUE)
install.packages("httpuv", dependencies = TRUE)
library(twitteR)
library(httpuv)
setup_twitter_oauth("YrOyTk5s9mBVkCNxjsL6QAAvR",
"	zOl3g5slS8fIBw1hWU3a8zeU1BFcS3g1wz7drIz2lbC8mydmgG"
)
setup_twitter_oauth(
"MTfL0uv6oBbtVBa3dPuR4PS51",
"T480vrOtvSK1XxGcPp20SdRoW99by3EGVvAapzyq8io0uH6lUh",
"191958252-uOisKMkvWHWmiTRQnf9d6XMww5wtZVtox1ShcjMm",
"9kTTYtORX4KnXk9SG4R9bQ1PpmQyBYEwmfvDksTh6Wht0")
trump_tweets <- userTimeline("realDonaldTrump", n = 3200)
trump_tweets
trump_tweets_df <- tbl_df(map_df(trump_tweets, as.data.frame))
library(dplyr)
library(purrr)
library(twitteR)
library(httpuv)
dplyr.tbl_df(map_df(trump_tweets, as.data.frame))
tbl_df(map_df(trump_tweets, as.data.frame))
trump_tweets_df <- tbl_df(map_df(trump_tweets, as.data.frame))
s, as.data.frame))
library(tidyr)
tweets <- trump_tweets_df %>%
select(id, statusSource, text, created) %>%
extract(statusSource, "source", "Twitter for (.*?)<") %>%
filter(source %in% c("iPhone", "Android"))
library(tidyr)
tweets <- trump_tweets_df %>%
select(id, statusSource, text, created) %>%
extract(statusSource, "source", "Twitter for (.*?)<") %>%
filter(source %in% c("iPhone", "Android"))
tweets
library(lubridate)
library(scales)
tweets %>%
count(source, hour = hour(with_tz(created, "EST"))) %>%
mutate(percent = n / sum(n)) %>%
ggplot(aes(hour, percent, color = source)) +
geom_line() +
scale_y_continuous(labels = percent_format()) +
labs(x = "Hour of day (EST)",
y = "% of tweets",
color = "")
x<-5
x
x<-5
x<-5
x
print(x)
x
x<- 1:20
x
install.packages("UsingR");
install.packages("reshape");
#install.packages("UsingR");
#install.packages("reshape");
library(UsingR);
data(galton);
library(reshape);
long<- melt(galton)
g <- ggplot(long, aes(x=value, fill = variable))
g <- g + geom_histogram(color ="black",binwidth=1)
g <- g + facet_grid(.~variable)
g
View(galton)
View(long)
View(long)
install.packages("manipulate");
library(manipulate)
library(manipulate);
myHist<- function(mu)
{
mse <- mean((galton$child - mu)^2)
g<- ggplot(galton, aes (x=child))
+geom_histogram(fill ="salmon", colour ="black", binwidth = 1)
g<- g + geom_vline(xintercept = mu, size= 3)
g<- g + ggtitle(paste("mu = ", mu , ", MSE =", round(mse, 2), sep =""))
g
}
manipulate(myHist(mu), mu = slider(62,74, step = 0.5))
library(manipulate);
myHist<- function(mu)
{
mse <- mean((galton$child - mu)^2)
g<- ggplot(galton, aes (x=child)) +geom_histogram(fill ="salmon", colour ="black", binwidth = 1)
g<- g + geom_vline(xintercept = mu, size= 3)
g<- g + ggtitle(paste("mu = ", mu , ", MSE =", round(mse, 2), sep =""))
g
}
manipulate(myHist(mu), mu = slider(62,74, step = 0.5))
install.packages("wordcloud")
install.packages("tm")
install.packages("SnowballC")
install.packages("RWeka")
install.packages("RSentiment")
install.packages("DT")
library(Rweka)
install.packages("wordcloud")
install.packages("tm")
install.packages("SnowballC")
install.packages("RWeka")
install.packages("RSentiment")
install.packages("DT")
install.packages("RWeka")
install.packages("RSentiment")
install.packages("DT")
library(twitteR)
setup_twitter_oauth(
"MTfL0uv6oBbtVBa3dPuR4PS51",
"T480vrOtvSK1XxGcPp20SdRoW99by3EGVvAapzyq8io0uH6lUh",
"191958252-uOisKMkvWHWmiTRQnf9d6XMww5wtZVtox1ShcjMm",
"9kTTYtORX4KnXk9SG4R9bQ1PpmQyBYEwmfvDksTh6Wht0")
trump_tweets <- userTimeline("realDonaldTrump", n = 3200)
trump_tweets
rm(trump_tweets)
tweets <- searchTwitter("#Guru", n = 5000)
tweets
Guru_df <- tbl_df(map_df(tweets, as.data.frame))
install.packages("tibble")
install.packages("tibble")
Guru_df <- tbl_df(map_df(tweets, as.data.frame))
library(dplyr)
library(purrr)
library(twitteR)
library(httpuv)
Guru_df <- tbl_df(map_df(tweets, as.data.frame))
Guru_df
library(wordcloud)
library(SnowballC)
library(RWeka)
library(RSentiment)
library(DT)
library(tm)
version()
sessionInfo()
update.packages(checkBuilt = T)
y
yy
yyy
sessionInfo()
sessionInfo()
library(Rweka)
library(dplyr)
library(purrr)
library(twitteR)
library(httpuv)
library(wordcloud)
library(SnowballC)
library(RWeka)
library(RSentiment)
library(DT)
library(tm)
install.packages("wordcloud")
install.packages("tm")
install.packages("SnowballC")
install.packages("RWeka")
install.packages("RSentiment")
install.packages("DT")
install.packages("tibble")
install.packages("SnowballC")
install.packages("RSentiment")
library("wordcloud", lib.loc="~/R/win-library/3.3")
library(Rweka)
install.packages("RWeka")
library(Rweka)
library(RWeka)
library(RWeka)
library(RWeka)
install.packages("rJava")
library(rJava)
library(twitteR)
library(rJava)
library(rJava)
installr()
library(RWeka)
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre1.8.0_121') # for 32-bit version
library(rJava)
Sys.setenv(JAVA_HOME='C:\\Program Files\\Java\\jre7') # for 64-bit version
Sys.setenv(JAVA_HOME='C:\\Program Files (x86)\\Java\\jre7') # for 32-bit version
library(rJava)
library(RWeka)
library(dplyr)
library(purrr)
library(twitteR)
library(httpuv)
library(wordcloud)
library(SnowballC)
library(RWeka)
library(RSentiment)
library(DT)
library(tm)
r1 = as.character(Guru_df$text)
set.seed(100)
sample = sample(r1, (length(r1)))
corpus = Corpus(VectorSource(list(sample)))
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, content_transformer(tolower))
corpus = tm_map(corpus, removeNumbers)
corpus = tm_map(corpus, stripWhitespace)
corpus = tm_map(corpus, removeWords, stopwords('english'))
corpus = tm_map(corpus, stemDocument)
dtm_up = DocumentTermMatrix(VCorpus(VectorSource(corpus[[1]]$content)))
freq_up <- colSums(as.matrix(dtm_up))
sentiments_up = calculate_sentiment(names(freq_up))
sentiments_up = cbind(sentiments_up, as.data.frame(freq_up))
sent_pos_up = sentiments_up[sentiments_up$sentiment == 'Positive',]
sent_neg_up = sentiments_up[sentiments_up$sentiment == 'Negative',]
cat("We have far lower negative Sentiments: ",sum(sent_neg_up$freq_up)," than positive: ",sum(sent_pos_up$freq_up))
DT::datatable(sent_pos_up)
if (Sys.getenv("JAVA_HOME")!="")
Sys.setenv(JAVA_HOME="")
library(rJava)
options(java.home="C:\\Program Files (x86)\\Java\\jre1.8.0_121\\")
library(rJava)
install.packages(MASS)
install.packages(DiscriMiner)
install.packages('MASS')
install.packages('DiscriMiner')
install.packages('lmtest')
install.packages('Deducer')
install.packages('pscl')
library(MASS)
library(DiscriMiner)
library(lmtest)
library(Deducer)
library(pscl)
install.packages('rJava')
install.packages('JGR')
install.packages('ggplot2')
install.packages('ggplot2')
library(pscl)
install.packages("wordcloud")
install.packages("tm")
install.packages("SnowballC")
install.packages("RWeka")
install.packages("RSentiment")
install.packages("DT")
install.packages("tibble")
install.packages("rJava")
install.packages(c("foreign", "Matrix", "Rcpp"))
download.file('https://www.nseindia.com/products/content/equities/equities/homepage_eq.htm',destfile = 'cm25MAY2017bhav.csv.zip')
download.file('https://www.nseindia.com/products/content/equities/equities/homepage_eq.htm',destfile = 'cm25MAY2017bhav.csv.zip')
## Let us first set the working directory path
setwd ("G:/GLCART/datafile/")
getwd()
## Data Import
raw_train_data <- read.table("DEV_SAMPLE.csv", sep = ",", header = T)
raw_test_data <- read.table("HOLDOUT_SAMPLE.csv", sep = ",", header = T)
names(raw_train_data)
head(raw_train_data,3)
c(traindata=nrow(raw_train_data),testdata=nrow(raw_test_data))
str(raw_train_data)
raw_train_data <- read.table("DEV_SAMPLE.csv", sep = ",", header = T)
setwd ("G:/GLCART/datafile/")
getwd()
setwd ("G:/GL/CART/datafile/")
getwd()
raw_train_data <- read.table("DEV_SAMPLE.csv", sep = ",", header = T)
raw_test_data <- read.table("HOLDOUT_SAMPLE.csv", sep = ",", header = T)
names(raw_train_data)
head(raw_train_data,3)
c(traindata=nrow(raw_train_data),testdata=nrow(raw_test_data))
str(raw_train_data)
NA_Count = sapply(Raw_data, function(y) sum(length(which(is.na(y)))))
NA_Count = sapply(raw_train_data, function(y) sum(length(which(is.na(y)))))
NA_Count
Col_Class=sapply(raw_train_data,class)
Col_Class
(sum(raw_train_data$Target)/nrow(raw_train_data))*100
library(rpart)
CART_model1 <- rpart(formula = Target ~ .,
data = raw_train_data[,-1], ## removing ID column, cause that doesn't help in classification
method = "class",
minsplit=100,
minbucket = 10,
cp = 0,
xval = 5
)
CART_model1
library(rattle)
fancyRpartPlot(CART_model1)
install.packages("rattle")
library(rattle)
fancyRpartPlot(CART_model1)
library(rattle)
fancyRpartPlot(CART_model1)
install.packages('rpart.plot')
library(rpart.plot)
fancyRpartPlot(CART_model1)
printcp(CART_model1)
plotcp(CART_model1)
