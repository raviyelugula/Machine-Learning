{
    "collab_server" : "",
    "contents" : "## Process followed. Considered the Test data as future data to see how our best model with stands to unknown data.\n## The Train data is used to build, tune, compare the models and give the best to production (handle the test data)\n## So the train data is splited, handle the missing data, SMOTE it, SCALE it and then feature it, in the same order before building the models.\n\nrequire(readxl) ## read Excel Files\nrequire(dplyr) ## data manupulation\nrequire(usdm) ## VIF \nrequire(ggplot2) ## Visualization\nrequire(caTools) ## split\nrequire(class) ## KNN\nrequire(DMwR) ## SMOTE\nrequire(smotefamily) ## BoderLine SMOTE\nrequire(caret) ## K-Fold, tuning\nrequire(e1071) ## SVM\nrequire(rpart) ## CART - Decision Tree\nrequire(randomForest) ## RandomForest\nrequire(neuralnet) ## ANN\nrequire(gridExtra) ## Multiple plots in single pannel\n\n# reading the data ----\nexcel_sheets(path = 'training.xlsx')\ntraindata = read_excel(path = 'training.xlsx', sheet = 'training')\nexcel_sheets('test.xlsx')\ntestdata = read_excel(path = 'test.xlsx', sheet = 'test')\n\n# rename cols, new features, data type adjustments ----\nData_Building <- function(data){\n  colnames(data) = c('RowID','DLQs','Utlz_UnsecLines','DebtRatio',\n                          'Credit_Loans','Dependents')\n  data = data %>% \n    dplyr::select(DLQs,Utlz_UnsecLines,DebtRatio,Credit_Loans,Dependents) \n  data$UUL_flag = ifelse(data$Utlz_UnsecLines>1,1,0)\n  data$DR_flag = ifelse(data$DebtRatio>1,1,0)\n  message('Original data formats:')\n  print(sapply(data,class))\n  data$Dependents = ifelse(data$Dependents =='NA',NA,data$Dependents)\n  data$Dependents = as.numeric(data$Dependents)\n  data[,c(1,6,7)] = data.frame(lapply(data[,c(1,6,7)],as.factor))\n  message('Final data formats:')\n  print(sapply(data,class))\n  return(data)\n}\ntraindata = Data_Building(traindata)\ntestdata = Data_Building(testdata)\n\n# Outliers Visualization\nBoxplot_outliers <- function(data){\n  par(mfrow=c(2,2))\n  B2 = boxplot(as.numeric(data$Utlz_UnsecLines),main=\"UnsecuredLines Utilization\",col=\"grey\", pars=list(outcol=\"red\"))\n  B3 = boxplot(as.numeric(data$DebtRatio), main = \"DebtRatio\",col=\"grey\", pars=list(outcol=\"red\"))\n  B4 = boxplot(as.numeric(data$Credit_Loans),main = \"Credit_Loans\",col=\"grey\", pars=list(outcol=\"red\"))\n  B5 = boxplot(as.numeric(data$Dependents), main = \"Dependents\",col=\"grey\", pars=list(outcol=\"red\"))\n  par(mfrow=c(1,1))\n}\nBoxplot_outliers(traindata)\n\n# seperating into two kinds outliers and normal data ----\nT1_traindata = subset(traindata, UUL_flag == 1 | DR_flag == 1)\nT2_traindata = subset(traindata, UUL_flag == 0 & DR_flag == 0)\n\nT1_testdata = subset(testdata, UUL_flag == 1 | DR_flag == 1)\nT2_testdata = subset(testdata, UUL_flag == 0 & DR_flag == 0)\n\n## T2 data modeling\n# Missing data checking ----\nMissing_data_Check <- function(data_set){\n  NA_Count = sapply(data_set,function(y) sum(length(which(is.na(y))))) \n  Null_Count = sapply(data_set,function(y) sum(length(which(is.null(y)))))\n  Length0_Count = sapply(data_set,function(y) sum(length(which(length(y)==0))))\n  Empty_Count = sapply(data_set,function(y) sum(length(which(y==''))))\n  Total_NonData = NA_Count+Null_Count+Length0_Count+Empty_Count\n  return( Total_NonData )\n}\nMissing_data_Check(T2_traindata)\n\n# Splitting the training data (SET1: build and tune the model) ~ (SET2: test the model) ----\nset.seed(123)\nsplit = sample.split(T2_traindata$Dependents, SplitRatio = 0.75)\nT2_traindata_Train = subset(T2_traindata, split == TRUE)\nT2_traindata_Test = subset(T2_traindata, split == FALSE)\n\n# Missing data handling ----\nMissing_data_handling <- function(data){\n  print(vif(data.frame(data[,c(2:4)])))\n  data_C = subset(data,!is.na(Dependents))\n  data_M = subset(data,is.na(Dependents))\n  \n  set.seed(123)\n  split = sample.split(data_C$Dependents, SplitRatio = 0.75)\n  data_C_Tr = subset(data_C, split == TRUE)\n  data_C_Te = subset(data_C, split == FALSE)\n  dependents = knn(train = scale(data_C_Tr[,c(2,3,4)]),\n                   test = scale(data_C_Te[,c(2,3,4)]),\n                   cl = as.factor(data_C_Tr$Dependents),\n                   k = 9,\n                   prob = F)\n  message(paste0('KNN Accuracy: ',round(length(which(data_C_Te$Dependents == dependents))/length(dependents),2)))\n  model = lm(Dependents~Utlz_UnsecLines+DebtRatio+Credit_Loans,\n             data=data_C_Tr)\n  dependents = round(predict(model,data_C_Te)) ## LR is not working as it gives all as 1\n  message(paste0('Linear regression Accuracy: ',round(length(which(data_C_Te$Dependents == dependents))/length(dependents),2)))\n  rm(list = c('data_C_Te','data_C_Tr'))\n  set.seed(1234)\n  dependents = knn(train = scale(data_C[,c(2,3,4)]),\n                   test = scale(data_M[,c(2,3,4)]),\n                   cl = as.factor(data_C$Dependents),\n                   k = 9,\n                   prob = F)\n  data_M$Dependents = dependents\n  data = rbind(data_C,data_M)\n  rm(list = c('data_C','data_M'))\n  message('Missing data in each column after handling:')\n  message(paste0(Missing_data_Check(data)))\n  data$Dependents = as.numeric(data$Dependents)\n  return(data)\n}\nT2_traindata_Test = Missing_data_handling(T2_traindata_Test)\nT2_traindata_Train = Missing_data_handling(T2_traindata_Train)\n\n# Target variable ratio check ----\nTwo_D_View <- function(data){\n  P1 = ggplot(data = data)+\n    geom_point(aes(x = Utlz_UnsecLines, y = DebtRatio,\n                   color = DLQs),show.legend = F)\n  P2 = ggplot(data = data)+\n    geom_point(aes(x = Dependents, y = Credit_Loans,\n                    color = DLQs),show.legend = F)\n  P3 = ggplot(data = data)+\n    geom_point(aes(x = Utlz_UnsecLines, y = Credit_Loans,\n                   color = DLQs),show.legend = F)\n  P4 = ggplot(data = data)+\n    geom_point(aes(x = Dependents, y = DebtRatio,\n                    color = DLQs),show.legend = F)\n  grid.arrange(P1, P2, P3,P4, ncol = 2, nrow = 2)\n}\nTarget_Ratio_Check <- function(data){\n  data$Dependents = as.numeric(data$Dependents)\n  message('Target ratio split:')\n  print(table(data$DLQs))\n  message('Target ratio:')\n  print(round(table(data$DLQs)[1]/sum(table(data$DLQs)),2))\n  Two_D_View(data)\n}\ndev.off()\nTarget_Ratio_Check(T2_traindata_Test) #95:5 \nTarget_Ratio_Check(T2_traindata_Train) #94:6\n# SMOTE for treating imbalance data set ----\nSMOTE_fitting <- function(data,o,u){\n  data_SMOTE = DMwR::SMOTE(DLQs~Utlz_UnsecLines+DebtRatio+Credit_Loans+Dependents,\n                     as.data.frame(data),perc.over = o,perc.under = u)\n  message('Original data ratio:')\n  print(round(table(data$DLQs)/length(data$DLQs),2))\n  message('SMOTEd data ratio:')\n  print(table(data_SMOTE$DLQs)/length(data_SMOTE$DLQs))\n  message('SMOTEd data split')\n  print(table(data_SMOTE$DLQs))\n  Two_D_View(data_SMOTE)\n  return(data_SMOTE)\n}\nTwo_D_View(T2_traindata_Test)\nT2_traindata_Test_SMOTEd = SMOTE_fitting(T2_traindata_Test,600,300)\nTwo_D_View(T2_traindata_Train)\nT2_traindata_Train_SMOTEd = SMOTE_fitting(T2_traindata_Train,600,300)\n\n# SMOTE has oversampled the major class area too - so trying borderline SMOTE ----\nBoderline_SMOTE_fitting <- function(data,i){\n  set.seed(1234)\n  data_SMOTE_B = BLSMOTE(as.data.frame(data[2:5]),as.numeric(data$DLQs),\n                                 K=4,C=3,dupSize=i,method =c(\"type1\"))\n  message('Boarderline SMOTE data Target variable ratio:')\n  print(round(table(data_SMOTE_B$data$class)/length(data_SMOTE_B$data$class),2))\n  message('Original data set Target ratio:')\n  print(round(table(data$DLQs)/length(data$DLQs),2))\n  data_SMOTE_BS = data_SMOTE_B$data\n  data_SMOTE_BS$DLQs = ifelse(data_SMOTE_BS$class == 1, 0, 1)\n  data_SMOTE_BS = data_SMOTE_BS[,c(6,1,2,3,4)]\n  data_SMOTE_BS$DLQs = as.factor(data_SMOTE_BS$DLQs)\n  Two_D_View(data_SMOTE_BS)\n  return(data_SMOTE_BS)\n}\nTwo_D_View(T2_traindata_Test)\nT2_traindata_Test_BS = Boderline_SMOTE_fitting(T2_traindata_Test,25) #70:30\n\nTwo_D_View(T2_traindata_Train)\nT2_traindata_Train_BS = Boderline_SMOTE_fitting(T2_traindata_Train,25) \nrm(list = c('T2_traindata_Test_SMOTEd','T2_traindata_Train_SMOTEd')) # Removing as SMOTE has overfitted the majored regions too\n\n# Building a Scaled data set for classification models ----\nScaling <- function(data){\n  data_scaled = data\n  data_scaled[-1] = scale(data_scaled[-1])\n  return(data_scaled)\n}\nT2_traindata_Test_BS_Scaled = Scaling(T2_traindata_Test_BS)\nT2_traindata_Train_BS_Scaled = Scaling(T2_traindata_Train_BS)\n# Logistic regression -- Specificity: Train - 78.14 K-fold Train - 77.78 Test - 86.29 ----\nT2_LR = glm( formula = DLQs~., \n             family = binomial,\n             data = T2_traindata_Train_BS_Scaled)\nprob_pred = predict(T2_LR, type = 'response', newdata = T2_traindata_Train_BS_Scaled[-1])\ny_pred = ifelse(prob_pred > 0.55, 1, 0)\nCM = table(T2_traindata_Train_BS_Scaled[,1],y_pred)\nLR_Speci_Train = CM[4]/(CM[4]+CM[2])\nround(LR_Speci_Train*100,2)\n\nrequire(lmtest)\nlrtest(T2_LR) # overall test i significant\nrequire(pscl)\npR2(T2_LR) # 35 - very good McFadden R2\n\nset.seed(1234)\nfolds = createFolds(T2_traindata_Train_BS_Scaled$DLQs, k = 10)\ncv = lapply(folds, function(x) {\n  training_fold = T2_traindata_Train_BS_Scaled[-x, ]\n  test_fold = T2_traindata_Train_BS_Scaled[x, ]\n  T2_LR_KF = glm( formula = DLQs~., \n                  family = binomial,\n                  data = training_fold)\n  prob_pred = predict(T2_LR_KF, type = 'response', newdata = test_fold[-1])\n  y_pred = ifelse(prob_pred > 0.55, 1, 0)\n  CM = table(test_fold[,1],y_pred)\n  temp = CM[4]/(CM[4]+CM[2])\n  return(temp)\n})\nLR_Speci_KF = mean(as.numeric(cv))\nround(LR_Speci_KF*100,2)\n\nprob_pred = predict(T2_LR, type = 'response', newdata = T2_traindata_Test_BS_Scaled[-1])\ny_pred = ifelse(prob_pred > 0.55, 1, 0)\nCM = table(T2_traindata_Test_BS_Scaled[,1],y_pred)\nLR_Speci_Test = CM[4]/(CM[4]+CM[2])\nround(LR_Speci_Test*100,2) # underfitted\n\n# KNN Classification -- Specificity:Train - xxxxx K-fold Train - 89.24 Test 18.38  ---- \nset.seed(1234)\ncaret_tune = train(form = DLQs~ ., data = T2_traindata_Train_BS_Scaled, method = 'knn')\ncaret_tune\ncaret_tune$bestTune # caret to tune for k value\n\ny_pred = knn(train =T2_traindata_Train_BS_Scaled[,-1],\n             test =T2_traindata_Test_BS_Scaled[,-1],\n             cl = T2_traindata_Train_BS_Scaled[, 1],\n             k = 7,\n             prob = TRUE)\nCM = table(T2_traindata_Test_BS_Scaled[,1],y_pred)\nKnn_Speci_Test = CM[4]/(CM[4]+CM[2])\nKnn_Speci_Test\n\nset.seed(1234)\nfolds = createFolds(T2_traindata_Train_BS_Scaled$DLQs, k = 10)\ncv = lapply(folds, function(x) {\n  training_fold = T2_traindata_Train_BS_Scaled[-x, ]\n  test_fold = T2_traindata_Train_BS_Scaled[x, ]\n  y_pred = knn(train =training_fold[,-1],\n               test =test_fold[,-1],\n               cl = training_fold[, 1],\n               k = 7,\n               prob = TRUE)\n  CM = table(test_fold[,1],y_pred)\n  temp = CM[4]/(CM[4]+CM[2])\n  return(temp)\n})\nKnn_Speci_KF = mean(as.numeric(cv)) #overfitted\n\n# SVM Classification -- Specificity:Train - 93.27 K-fold Train - 88.8 Test 8.723  ---- \nset.seed(1234)\ncaret_tune = train(form = DLQs~ ., data = T2_traindata_Train_BS_Scaled, method = 'svmLinearWeights')\ncaret_tune\ncaret_tune$bestTune # caret to tune for cost and weight value - cost is 0.25\nset.seed(1234)\ntune_svm_kernal = tune(svm, DLQs~ ., data = T2_traindata_Train_BS_Scaled,\n                       kernal = 'radial',\n                       ranges = list(cost = c(0.1,0.4,0.8,1,3,5,10,50,100), # penalising factor for missclassification, high c => low bias, high viariance, default is 1\n                                     gamma = c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,2,4))) # smoothening the boundary shape sharpness, low gama => pointy bounday, low bias, high variance, default 1/dimensions\nsummary(tune_svm_kernal) # tuned parameters says cost 3 and gamma 4\nset.seed(1234)\ntune_svm_kernal = tune(svm, DLQs~ ., data = T2_traindata_Train_BS_Scaled,\n                       kernal = 'sigmoid',\n                       ranges = list(cost = c(0.1,0.4,0.8,1,3,5,10,50,100), \n                                     gamma = c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,2,4))) \nsummary(tune_svm_kernal) # tuned parameters says cost 3 and gamma 4\nset.seed(1234)\ntune_svm_kernal = tune(svm, DLQs~ ., data = T2_traindata_Train_BS_Scaled,\n                       kernal = 'polynomial',\n                       ranges = list(ccost = c(0.1,0.4,0.8,1,3,5,10,50,100),\n                                     gamma = c(0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,2,4),\n                                     degree = c(2,3,4,5,6)))\nsummary(tune_svm_kernal) # tuned parameters says cost 0.1 and gamma 4 and degree 2\n\nfor(svmType in c('C-classification','nu-classification')){\n  for(svmKernal in c('linear','polynomial','radial','sigmoid')){\n    set.seed(1234)\n    folds = createFolds(T2_traindata_Train_BS_Scaled$DLQs, k = 10)\n    cv = lapply(folds, function(x) {\n      training_fold = T2_traindata_Train_BS_Scaled[-x, ]\n      test_fold = T2_traindata_Train_BS_Scaled[x, ]\n      if(svmKernal == 'radial'){\n        T2_SVM = svm(formula = DLQs ~ .,\n                     data = training_fold,\n                     type = 'C-classification',\n                     kernel = svmKernal, cost = 3,gamma = 4)\n        y_pred = predict(T2_SVM, newdata = test_fold[-1])\n      }else if(svmKernal=='sigmoid'){\n        T2_SVM = svm(formula = DLQs ~ .,\n                     data = training_fold,\n                     type = 'C-classification',\n                     kernel = svmKernal, cost = 3,gamma = 4)\n        y_pred = predict(T2_SVM, newdata = test_fold[-1])\n      }else if(svmKernal=='polynomial'){\n        T2_SVM = svm(formula = DLQs ~ .,\n                     data = training_fold,\n                     type = 'C-classification',\n                     kernel = svmKernal, cost = 0.1,gamma = 4 ,degre = 2)\n        y_pred = predict(T2_SVM, newdata = test_fold[-1])\n      }else{\n        T2_SVM = svm(formula = DLQs ~ .,\n                     data = training_fold,\n                     type = 'C-classification',\n                     kernel = svmKernal, cost =0.25)\n        y_pred = predict(T2_SVM, newdata = test_fold[-1])\n      }\n      CM = table(test_fold[,1],y_pred)\n      temp = CM[4]/(CM[4]+CM[2])\n      return(temp)\n    })\n    specificity_SVM = round(mean(as.numeric(cv)),5)*100\n    print.noquote(paste0(svmKernal,'-kernal ',svmType,' has K-fold specificity of ',specificity_SVM))\n  }\n} # choose radial kernal with C-Classification as it has highest 88.8\n\n# [1] linear-kernal C-classification has K-fold specificity of 83.961\n# [1] polynomial-kernal C-classification has K-fold specificity of 5.446\n# [1] radial-kernal C-classification has K-fold specificity of 88.8\n# [1] sigmoid-kernal C-classification has K-fold specificity of 37.542\n# [1] linear-kernal nu-classification has K-fold specificity of 83.961\n# [1] polynomial-kernal nu-classification has K-fold specificity of 5.446\n# [1] radial-kernal nu-classification has K-fold specificity of 88.8\n# [1] sigmoid-kernal nu-classification has K-fold specificity of 37.542\nT2_SVM = svm(formula = DLQs ~ .,\n             data = T2_traindata_Train_BS_Scaled,\n             type = 'C-classification',\n             kernel = 'radial', cost= 3, gamma= 4)\ny_pred = predict(T2_SVM, newdata = T2_traindata_Train_BS_Scaled[-1])\nCM = table(T2_traindata_Train_BS_Scaled[,1],y_pred)\nSVM_Speci_Train = CM[4]/(CM[4]+CM[2])\n\ny_pred = predict(T2_SVM, newdata = T2_traindata_Test_BS_Scaled[-1])\nCM = table(T2_traindata_Test_BS_Scaled[,1],y_pred)\nSVM_Speci_Test = CM[4]/(CM[4]+CM[2]) # dropped in Test, overfitted, but will consider for Test set, as k-fold is close to train_test\n\n# Naive Bayes -- Specificity:Train - 81.1 K-fold Train - 81.0 Test 87.53   ----\nset.seed(1234)\nfolds = createFolds(T2_traindata_Train_BS_Scaled$DLQs, k = 10)\ncv = lapply(folds, function(x) {\n  training_fold = T2_traindata_Train_BS_Scaled[-x, ]\n  test_fold = T2_traindata_Train_BS_Scaled[x, ]\n  T2_NB = naiveBayes(x = training_fold[-1],\n                     y = training_fold$DLQs)\n  y_pred = predict(T2_NB, newdata = test_fold[-1])\n  CM = table(test_fold[,1],y_pred)\n  temp = CM[4]/(CM[4]+CM[2])\n  return(temp)\n})\nNB_Speci_KF = round(mean(as.numeric(cv)),5)*100\n\nT2_NB = naiveBayes(x = T2_traindata_Train_BS_Scaled[-1],\n                   y = T2_traindata_Train_BS_Scaled$DLQs)\n\ny_pred = predict(T2_NB, newdata = T2_traindata_Train_BS_Scaled[-1])\nCM = table(T2_traindata_Train_BS_Scaled[,1],y_pred)\nNB_Speci_Train = CM[4]/(CM[4]+CM[2])\n\ny_pred = predict(T2_NB, newdata = T2_traindata_Test_BS_Scaled[-1])\nCM = table(T2_traindata_Test_BS_Scaled[,1],y_pred)\nNB_Speci_Test = CM[4]/(CM[4]+CM[2]) # moves to predict against test\n\n# CART -- Specificity:Train - 75.36 K-fold Train - 78.59 Test 39.25    --------\ncaret_tune = train(form = DLQs~ ., data = T2_traindata_Train_BS_Scaled, method = 'rpart')\ncaret_tune\ncaret_tune$bestTune # CP - Tunning \n\nT2_CART_temp = rpart(formula = DLQs ~ ., \n                     data = T2_traindata_Train_BS_Scaled, \n                     method = \"class\", \n                     minsplit= 225, \n                     cp = 0, \n                     xval = 7)\nprintcp(T2_CART_temp)\nplotcp(T2_CART_temp)\nT2_CART = prune(T2_CART_temp, cp= 0.03315412186 ,\"CP\")\ny_pred = predict(T2_CART, newdata = T2_traindata_Train_BS_Scaled[-1], type='class')\nCM = table(T2_traindata_Train_BS_Scaled[,1],y_pred)\nCART_Speci_Train = CM[4]/(CM[4]+CM[2])\n\nset.seed(1234)\nfolds = createFolds(T2_traindata_Train_BS_Scaled$DLQs, k = 10)\ncv = lapply(folds, function(x) {\n  training_fold = T2_traindata_Train_BS_Scaled[-x, ]\n  test_fold = T2_traindata_Train_BS_Scaled[x, ]\n  T2_CART_temp = rpart(formula = DLQs ~ ., \n                       data = training_fold, \n                       method = \"class\", \n                       minsplit= 225, \n                       cp = 0.05284974, \n                       xval = 7)\n  y_pred = predict(T2_CART_temp, newdata = test_fold[-1], type='class')\n  CM = table(test_fold[,1],y_pred)\n  temp = CM[4]/(CM[4]+CM[2])\n  return(temp)\n})\nCART_Speci_KF = round(mean(as.numeric(cv)),5)*100\n\ny_pred = predict(T2_CART, newdata = T2_traindata_Test_BS_Scaled[-1],type='class')\nCM = table(T2_traindata_Test_BS_Scaled[,1],y_pred)\nCART_Speci_Test = CM[4]/(CM[4]+CM[2]) # overfitted\n\n# Random Forest -- Specificity:Train - 88.2 K-fold Train - 83.96 Test 40.5 ------\nset.seed(1234)\nT2_RF = randomForest(DLQs ~ ., data = T2_traindata_Train_BS_Scaled, \n                     ntree=500, mtry = 2, nodesize = 40,\n                     importance=TRUE)\nplot(T2_RF) ## 150 tree from OOB\ncaret_tune = train(form = DLQs~ ., data = T2_traindata_Train_BS_Scaled, method = 'rf')\ncaret_tune\ncaret_tune$bestTune # mtry - Tunning \n\nset.seed(1234)\nT2_RF = tuneRF(x = T2_traindata_Train_BS_Scaled[,-1], \n               y=T2_traindata_Train_BS_Scaled$DLQs,\n               mtryStart = 2,\n               ntreeTry=150, \n               stepFactor = 1, ## 1st try 2 variables, next 4 , next 5 , next 6 MtryStart*Stepfactor \n               improve = 0.001, ## delta OOB \n               trace=TRUE, \n               plot = TRUE,\n               doBest = TRUE,\n               nodesize = 20, \n               importance=TRUE\n) # random Forest tuning also lead to mtry = 2\n\ny_pred = predict(T2_RF, newdata = T2_traindata_Train_BS_Scaled[-1], type='class')\nCM = table(T2_traindata_Train_BS_Scaled[,1],y_pred)\nRF_Speci_Train = CM[4]/(CM[4]+CM[2])\n\nset.seed(1234)\nfolds = createFolds(T2_traindata_Train_BS_Scaled$DLQs, k = 10)\ncv = lapply(folds, function(x) {\n  training_fold = T2_traindata_Train_BS_Scaled[-x, ]\n  test_fold = T2_traindata_Train_BS_Scaled[x, ]\n  T2_RF_temp = randomForest(DLQs ~ ., data = training_fold, \n                            ntree=150, mtry = 2, nodesize = 40)\n  y_pred = predict(T2_RF_temp, newdata = test_fold[-1], type='class')\n  CM = table(test_fold[,1],y_pred)\n  temp = CM[4]/(CM[4]+CM[2])\n  return(temp)\n})\nRF_Speci_KF = round(mean(as.numeric(cv)),5)*100\n\ny_pred = predict(T2_RF, newdata = T2_traindata_Test_BS_Scaled[-1], type='class')\nCM = table(T2_traindata_Test_BS_Scaled[,1],y_pred)\nRF_Speci_Test = CM[4]/(CM[4]+CM[2]) # overfitted\n\n# ANN -- Specificity:Train - 82.44 K-fold Train - xxxxxx Test 38.31 ----\ntraining_set_scaled_ANN = T2_traindata_Train_BS_Scaled\ntraining_set_scaled_ANN$DLQs = as.numeric(as.character(training_set_scaled_ANN$DLQs))\ntest_set_scaled_ANN = T2_traindata_Test_BS_Scaled\ntest_set_scaled_ANN$DLQs = as.numeric(as.character(test_set_scaled_ANN$DLQs))\n\nn = names(training_set_scaled_ANN)\nlong_formula = as.formula(paste(\"DLQs ~\", paste(n[!n %in% \"DLQs\"], collapse = \" + \")))\nset.seed(123)\nT2_ANN = neuralnet(formula = long_formula,\n                   data = training_set_scaled_ANN,\n                   hidden = c(4,4),\n                   err.fct = \"sse\",\n                   linear.output = FALSE,\n                   lifesign = \"full\",\n                   lifesign.step = 1,\n                   threshold = 0.05,\n                   stepmax = 100000)\nplot(T2_ANN)\ny_pred = ifelse(T2_ANN$net.result[[1]] >= 0.5,1,0)\nCM = table(training_set_scaled_ANN[,1],y_pred)\nANN_Speci_Train = CM[4]/(CM[4]+CM[2])\nANN_Speci_Train\n\ny_pred = compute(T2_ANN,test_set_scaled_ANN[,-1])\ny_pred = ifelse(y_pred$net.result >= 0.5,1,0)\nCM = table(test_set_scaled_ANN[,1],y_pred)\nANN_Speci_Test = CM[4]/(CM[4]+CM[2])\nANN_Speci_Test # overfitted\n\n# Test data prep LR: 57.67 KNN: 46 SVM:31 NB: 73.33 CART: 75.67 RF: 47.34 ANN: 58.667 ----\nMissing_data_Check(T2_testdata)\ndata_C = subset(T2_testdata,!is.na(Dependents))\ndata_M = subset(T2_testdata,is.na(Dependents))\ndependents = knn(train = scale(data_C[,c(2,3,4)]),\n                 test = as.matrix(cbind(scale(data_M[2]), data_M[3], scale(data_M[4]))),\n                 cl = as.factor(data_C$Dependents),\n                 k = 9,\n                 prob = F)\ndata_M$Dependents = dependents\nT2_testdata = rbind(data_C,data_M)\nrm(list = c('data_C','data_M'))\nMissing_data_Check(T2_testdata)\nT2_testdata$Dependents = as.numeric(T2_testdata$Dependents)\nTwo_D_View(T2_testdata)\nset.seed(1234)\nT2_testdata_BS = Boderline_SMOTE_fitting(T2_testdata,14)\nT2_testdata_BS_Scaled = Scaling(T2_testdata_BS)\n\nT2_traindata_Complete_BS_Scaled = rbind(T2_traindata_Train_BS_Scaled, \n                                        T2_traindata_Test_BS_Scaled)\nT2_NB = naiveBayes(x = T2_traindata_Complete_BS_Scaled[-1],\n                   y = T2_traindata_Complete_BS_Scaled$DLQs)\ny_pred = predict(T2_NB, newdata = T2_testdata_BS_Scaled[-1])\nCM = table(T2_testdata_BS_Scaled[,1],y_pred)\nNB_Speci_Hold = CM[4]/(CM[4]+CM[2]) #79.33\n\n#### Below models are not ran due to unstable models -----\n\n# T2_LR = glm( formula = DLQs~., \n#              family = binomial,\n#              data = T2_traindata_Complete_BS_Scaled)\n# prob_pred = predict(T2_LR, type = 'response', newdata = T2_testdata_BS_Scaled[-1])\n# y_pred = ifelse(prob_pred > 0.55, 1, 0)\n# CM = table(T2_testdata_BS_Scaled$DLQs,y_pred)\n# LR_Speci_Hold = CM[4]/(CM[4]+CM[2])\n# round(LR_Speci_Hold*100,2) # 57.67\n\n# y_pred = knn(train =T2_traindata_Complete_BS_Scaled[,-1],\n#              test =T2_testdata_BS_Scaled[,-1],\n#              cl = T2_traindata_Complete_BS_Scaled[, 1],\n#              k = 9,\n#              prob = TRUE)\n# CM = table(T2_testdata_BS_Scaled[,1],y_pred)\n# Knn_Speci_Hold = CM[4]/(CM[4]+CM[2])\n# round(Knn_Speci_Hold*100,2) # 46\n\n# T2_SVM = svm(formula = DLQs ~ .,\n#              data = T2_traindata_Complete_BS_Scaled,\n#              type = 'C-classification',\n#              kernel = 'radial', cost= 3, gamma= 4)\n# y_pred = predict(T2_SVM, newdata = T2_testdata_BS_Scaled[-1])\n# CM = table(T2_testdata_BS_Scaled[,1],y_pred)\n# SVM_Speci_Hold = CM[4]/(CM[4]+CM[2]) #31\n\n# T2_CART = rpart(formula = DLQs ~ ., \n#                      data = T2_traindata_Complete_BS_Scaled, \n#                      method = \"class\", \n#                      minsplit= 225, \n#                      cp = 0.05284974, \n#                      xval = 7)\n# y_pred = predict(T2_CART, newdata = T2_testdata_BS_Scaled[-1],type='class')\n# CM = table(T2_testdata_BS_Scaled[,1],y_pred)\n# CART_Speci_Hold = CM[4]/(CM[4]+CM[2])\n\n# T2_RF = randomForest(DLQs ~ ., data = T2_traindata_Complete_BS_Scaled,\n#                      ntree=150, mtry = 2, nodesize = 40,\n#                      importance=TRUE)\n# y_pred = predict(T2_RF, newdata = T2_testdata_BS_Scaled[-1], type='class')\n# CM = table(T2_testdata_BS_Scaled[,1],y_pred)\n# RF_Speci_Hold = CM[4]/(CM[4]+CM[2]) # 47.34\n\n# training_set_scaled_ANN = T2_traindata_Complete_BS_Scaled\n# training_set_scaled_ANN$DLQs = as.numeric(as.character(training_set_scaled_ANN$DLQs))\n# test_set_scaled_ANN = T2_testdata_BS_Scaled\n# test_set_scaled_ANN$DLQs = as.numeric(as.character(test_set_scaled_ANN$DLQs))\n# \n# n = names(training_set_scaled_ANN)\n# long_formula = as.formula(paste(\"DLQs ~\", paste(n[!n %in% \"DLQs\"], collapse = \" + \")))\n# set.seed(123)\n# T2_ANN = neuralnet(formula = long_formula,\n#                    data = training_set_scaled_ANN,\n#                    hidden = c(4,4),\n#                    err.fct = \"sse\",\n#                    linear.output = FALSE,\n#                    lifesign = \"full\",\n#                    lifesign.step = 1,\n#                    threshold = 0.05,\n#                    stepmax = 100000)\n# y_pred = compute(T2_ANN,test_set_scaled_ANN[,-1])\n# y_pred = ifelse(y_pred$net.result >= 0.5,1,0)\n# CM = table(test_set_scaled_ANN[,1],y_pred)\n# ANN_Speci_Hold = CM[4]/(CM[4]+CM[2])\n# ANN_Speci_Hold # 58.667\n\n\n\n\n\n\n\n\n",
    "created" : 1510352741567.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4194750804",
    "id" : "C6CF3B59",
    "lastKnownWriteTime" : 1510506029,
    "last_content_update" : 1510506029826,
    "path" : "~/GitHub/MachineLearningExamples/Classification/Classification_Modeling_SPLIT_SMOTE.R",
    "project_path" : "Classification_Modeling_SPLIT_SMOTE.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}